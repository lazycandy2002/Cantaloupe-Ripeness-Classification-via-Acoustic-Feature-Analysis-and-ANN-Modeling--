{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aebe63-9607-4690-a4cb-3102310215a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c2529a-71ff-4b30-b78b-02b181d7dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CantaloupeRipenessClassifier:\n",
    "    \"\"\"\n",
    "    A classifier for determining cantaloupe ripeness using MFCC-based features and an SVM.\n",
    "    \"\"\"\n",
    "\n",
    "    class CantaloupeRipenessClassifier:\n",
    "\"\"\"\n",
    "A classifier for determining cantaloupe ripeness using enriched audio features and an SVM.\n",
    "\"\"\"\n",
    "\n",
    "```\n",
    "def __init__(self, sample_rate=44100, duration=7, n_mfcc=13):\n",
    "    self.sample_rate = sample_rate\n",
    "    self.duration = duration\n",
    "    self.n_mfcc = n_mfcc\n",
    "    self.model = None\n",
    "    self.scaler = None\n",
    "\n",
    "def extract_features(self, file_path):\n",
    "    \"\"\"\n",
    "    Extracts rich audio features for classification.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=self.sample_rate, duration=self.duration)\n",
    "\n",
    "        # MFCC\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "        mfcc_std = np.std(mfcc, axis=1)\n",
    "\n",
    "        # Delta & Delta-Delta\n",
    "        delta = librosa.feature.delta(mfcc)\n",
    "        delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "        delta_mean = np.mean(delta, axis=1)\n",
    "        delta_std = np.std(delta, axis=1)\n",
    "        delta2_mean = np.mean(delta2, axis=1)\n",
    "        delta2_std = np.std(delta2, axis=1)\n",
    "\n",
    "        # Other spectral features\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
    "        zcr_mean = np.mean(zcr)\n",
    "\n",
    "        centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "        bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "        rms = librosa.feature.rms(y=y)[0]\n",
    "\n",
    "        spectral_features = [\n",
    "            np.mean(centroid), np.std(centroid),\n",
    "            np.mean(bandwidth), np.std(bandwidth),\n",
    "            np.mean(rolloff), np.std(rolloff),\n",
    "            np.mean(rms), np.std(rms),\n",
    "            zcr_mean\n",
    "        ]\n",
    "\n",
    "        features = np.concatenate([\n",
    "            mfcc_mean, mfcc_std,\n",
    "            delta_mean, delta_std,\n",
    "            delta2_mean, delta2_std,\n",
    "            spectral_features\n",
    "        ])\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_dataset(self, ripe_dir, unripe_dir):\n",
    "    \"\"\"\n",
    "    Load ripe and unripe samples from directories.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for label, directory in zip([1, 0], [ripe_dir, unripe_dir]):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.wav'):\n",
    "                path = os.path.join(directory, file)\n",
    "                feat = self.extract_features(path)\n",
    "                if feat is not None:\n",
    "                    features.append(feat)\n",
    "                    labels.append(label)\n",
    "\n",
    "    X = np.array(features)\n",
    "    y = np.array(labels)\n",
    "    return X, y\n",
    "\n",
    "def train_model(self, X, y, tune=False):\n",
    "    \"\"\"\n",
    "    Train SVM classifier. Optionally perform grid search for hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    self.scaler = StandardScaler()\n",
    "    X_scaled = self.scaler.fit_transform(X)\n",
    "\n",
    "    if tune:\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'degree': [2, 3, 4],\n",
    "            'gamma': ['scale', 'auto', 0.01, 0.001],\n",
    "            'class_weight': [None, 'balanced']\n",
    "        }\n",
    "        grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "        grid.fit(X_scaled, y)\n",
    "        self.model = grid.best_estimator_\n",
    "        print(f\"Best parameters: {grid.best_params_}\")\n",
    "    else:\n",
    "        self.model = SVC(kernel='poly', degree=3, C=1.0)\n",
    "        self.model.fit(X_scaled, y)\n",
    "\n",
    "def evaluate_model(self, X, y):\n",
    "    \"\"\"\n",
    "    Print classification report and display confusion matrix.\n",
    "    \"\"\"\n",
    "    X_scaled = self.scaler.transform(X)\n",
    "    predictions = self.model.predict(X_scaled)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, predictions, target_names=['Unripe', 'Ripe']))\n",
    "\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Unripe', 'Ripe'])\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "def save_model(self, model_path='ripeness_model.pkl', scaler_path='scaler.pkl'):\n",
    "    \"\"\"\n",
    "    Save model and scaler.\n",
    "    \"\"\"\n",
    "    joblib.dump(self.model, model_path)\n",
    "    joblib.dump(self.scaler, scaler_path)\n",
    "    print(f\"Model saved to {model_path}, scaler saved to {scaler_path}\")\n",
    "\n",
    "def load_model(self, model_path='ripeness_model.pkl', scaler_path='scaler.pkl'):\n",
    "    \"\"\"\n",
    "    Load model and scaler.\n",
    "    \"\"\"\n",
    "    self.model = joblib.load(model_path)\n",
    "    self.scaler = joblib.load(scaler_path)\n",
    "    print(\"Model and scaler loaded.\")\n",
    "\n",
    "def predict_file(self, file_path):\n",
    "    \"\"\"\n",
    "    Predict the ripeness of a single audio file.\n",
    "    \"\"\"\n",
    "    features = self.extract_features(file_path)\n",
    "    if features is None:\n",
    "        return \"Error\"\n",
    "    features_scaled = self.scaler.transform([features])\n",
    "    prediction = self.model.predict(features_scaled)[0]\n",
    "    return 'Ripe' if prediction == 1 else 'Unripe'\n",
    "\n",
    "def plot_feature_distributions(self, X, y):\n",
    "    \"\"\"\n",
    "    Plot feature distributions using seaborn.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(X)\n",
    "    df['Label'] = y\n",
    "    df['Label'] = df['Label'].map({1: 'Ripe', 0: 'Unripe'})\n",
    "\n",
    "    melted_df = df.melt(id_vars='Label', var_name='Feature', value_name='Value')\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.boxplot(x='Feature', y='Value', hue='Label', data=melted_df)\n",
    "    plt.title('Feature Distributions by Ripeness')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e147bf1-211e-4863-b4e8-cd4e63c92edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    classifier = CantaloupeRipenessClassifier()\n",
    "\n",
    "    # Paths to your dataset\n",
    "    ripe_dir = 'data/ripe'\n",
    "    unripe_dir = 'data/unripe'\n",
    "\n",
    "    print(\"Loading dataset...\")\n",
    "    X, y = classifier.load_dataset(ripe_dir, unripe_dir)\n",
    "    \n",
    "    if X.size == 0 or y.size == 0:\n",
    "        print(\"Dataset loading failed. Check if the audio files exist and are accessible.\")\n",
    "    else:\n",
    "        print(f\"Loaded dataset with {X.shape[0]} samples and {X.shape[1]} features.\")\n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        print(\"Training model with hyperparameter tuning...\")\n",
    "        classifier.train_model(X_train, y_train, tune=True)\n",
    "\n",
    "        print(\"Evaluating model...\")\n",
    "        classifier.evaluate_model(X_test, y_test)\n",
    "\n",
    "        print(\"Visualizing feature distributions...\")\n",
    "        classifier.plot_feature_distributions(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0958a47-e505-426f-b3e6-1be28d2ef252",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Save model\n",
    "    classifier.save_model()\n",
    "\n",
    "    # Predict an example\n",
    "    example_file = 'example.wav'\n",
    "    result = classifier.predict_file(example_file)\n",
    "    print(f\"{example_file} is classified as: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ba28d-cb83-4c85-ac43-2ce08d80eff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
